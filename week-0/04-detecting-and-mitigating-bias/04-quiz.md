# Lesson: Detecting and Mitigating Bias

### Multiple Choice Questions

**Question 1:**  
Which of the following best describes algorithmic bias in AI systems?

a) Human judgment errors that occur during data selection and interpretation  
b) Systematic errors in sampling that cause expected values to deviate from true population values  
c) Systematic differences in model outputs for different demographic groups  
d) Cognitive errors made by model developers during feature engineering  


**Question 2:**  
Which statistical test is most appropriate for assessing if categorical distributions in your sample match expected population distributions?

a) K-S test  
b) Chi-square test  
c) ANOVA  
d) Linear regression  


**Question 3:**  
What does the fairness metric "Equal Opportunity" measure?

a) Equal positive prediction rates across groups  
b) Equal true positive rates across groups  
c) Equal false positive rates across groups  
d) Equal positive predictive values across groups  


**Question 4:**  
Which bias mitigation approach adjusts prediction thresholds differently for various demographic groups to achieve fairness?

a) Balanced sampling  
b) Adversarial debiasing  
c) Threshold adjustment  
d) Feature transformation  


**Question 5:**  
In the bias propagation chain, what typically causes statistical bias?

a) Algorithmic limitations  
b) Cognitive assumptions  
c) Model architecture  
d) Hardware constraints  


### Multiple Answer Questions

**Question 6:**  
Which of the following are types of bias discussed in the lesson? (Select all that apply)

a) Cognitive bias  
b) Statistical bias  
c) Algorithmic bias  
d) Structural bias  


**Question 7:**  
Which techniques can be used to detect sampling bias in datasets? (Select all that apply)

a) Chi-square tests  
b) Kolmogorov-Smirnov tests  
c) Propensity scoring  
d) Gradient boosting  


**Question 8:**  
Which of the following are valid pre-processing bias mitigation techniques? (Select all that apply)

a) Balanced sampling  
b) Reweighting  
c) Feature transformation  
d) Threshold adjustment  


**Question 9:**  
Which fairness metrics focus on equalizing error rates across demographic groups? (Select all that apply)

a) Demographic Parity  
b) Equal Opportunity  
c) Equalized Odds  
d) Predictive Parity  


**Question 10:**  
Which approaches are classified as in-processing bias mitigation techniques? (Select all that apply)

a) Adversarial debiasing  
b) Fairness constraints  
c) Threshold adjustment  
d) Balanced sampling  
